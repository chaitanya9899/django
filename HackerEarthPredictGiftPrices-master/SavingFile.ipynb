{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import date\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular import add_datepart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../HackerEarthPredictGiftPrices/dataset/train.csv')\n",
    "\n",
    "test = pd.read_csv('../HackerEarthPredictGiftPrices/dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gift_id</th>\n",
       "      <th>gift_type</th>\n",
       "      <th>gift_category</th>\n",
       "      <th>gift_cluster</th>\n",
       "      <th>instock_date</th>\n",
       "      <th>stock_update_date</th>\n",
       "      <th>lsg_1</th>\n",
       "      <th>lsg_2</th>\n",
       "      <th>lsg_3</th>\n",
       "      <th>lsg_4</th>\n",
       "      <th>lsg_5</th>\n",
       "      <th>lsg_6</th>\n",
       "      <th>uk_date1</th>\n",
       "      <th>uk_date2</th>\n",
       "      <th>is_discounted</th>\n",
       "      <th>volumes</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GF_11156</td>\n",
       "      <td>61</td>\n",
       "      <td>534</td>\n",
       "      <td>3942</td>\n",
       "      <td>2014-02-21 05:07:06.000</td>\n",
       "      <td>2016-11-09 15:49:51.000</td>\n",
       "      <td>3377</td>\n",
       "      <td>5221</td>\n",
       "      <td>504</td>\n",
       "      <td>1912</td>\n",
       "      <td>10</td>\n",
       "      <td>554</td>\n",
       "      <td>2014-02-24 08:07:06.000</td>\n",
       "      <td>2014-02-24 07:07:06.000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>175.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GF_11157</td>\n",
       "      <td>61</td>\n",
       "      <td>534</td>\n",
       "      <td>3942</td>\n",
       "      <td>2014-02-21 06:07:06.000</td>\n",
       "      <td>2016-11-11 13:49:51.000</td>\n",
       "      <td>3377</td>\n",
       "      <td>5221</td>\n",
       "      <td>504</td>\n",
       "      <td>1912</td>\n",
       "      <td>10</td>\n",
       "      <td>554</td>\n",
       "      <td>2014-02-22 07:07:06.000</td>\n",
       "      <td>2014-02-24 06:07:06.000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GF_15689</td>\n",
       "      <td>584</td>\n",
       "      <td>262</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-02-21 09:30:21.000</td>\n",
       "      <td>2016-03-24 14:46:18.000</td>\n",
       "      <td>5290</td>\n",
       "      <td>1579</td>\n",
       "      <td>3203</td>\n",
       "      <td>1912</td>\n",
       "      <td>9</td>\n",
       "      <td>1578</td>\n",
       "      <td>2016-01-26 00:04:45.000</td>\n",
       "      <td>2016-03-18 02:00:00.000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GF_11155</td>\n",
       "      <td>61</td>\n",
       "      <td>534</td>\n",
       "      <td>3942</td>\n",
       "      <td>2014-02-22 05:07:06.000</td>\n",
       "      <td>2016-11-10 16:49:51.000</td>\n",
       "      <td>3377</td>\n",
       "      <td>5221</td>\n",
       "      <td>504</td>\n",
       "      <td>1912</td>\n",
       "      <td>10</td>\n",
       "      <td>554</td>\n",
       "      <td>2016-11-07 13:49:51.000</td>\n",
       "      <td>2016-11-06 04:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>172.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GF_11158</td>\n",
       "      <td>61</td>\n",
       "      <td>534</td>\n",
       "      <td>3942</td>\n",
       "      <td>2014-02-22 07:07:06.000</td>\n",
       "      <td>2016-11-10 13:49:51.000</td>\n",
       "      <td>3377</td>\n",
       "      <td>5221</td>\n",
       "      <td>504</td>\n",
       "      <td>1912</td>\n",
       "      <td>9</td>\n",
       "      <td>554</td>\n",
       "      <td>2016-11-07 15:49:51.000</td>\n",
       "      <td>2016-11-06 01:00:00.000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20274</th>\n",
       "      <td>GF_10269</td>\n",
       "      <td>105</td>\n",
       "      <td>704</td>\n",
       "      <td>6448</td>\n",
       "      <td>2016-11-12 13:46:42.000</td>\n",
       "      <td>2016-11-17 10:46:42.000</td>\n",
       "      <td>2055</td>\n",
       "      <td>6883</td>\n",
       "      <td>995</td>\n",
       "      <td>1912</td>\n",
       "      <td>10</td>\n",
       "      <td>1899</td>\n",
       "      <td>2016-11-14 14:46:42.000</td>\n",
       "      <td>2016-11-11 03:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20275</th>\n",
       "      <td>GF_5854</td>\n",
       "      <td>1220</td>\n",
       "      <td>526</td>\n",
       "      <td>817</td>\n",
       "      <td>2016-11-12 13:46:47.000</td>\n",
       "      <td>2016-11-18 13:46:47.000</td>\n",
       "      <td>8323</td>\n",
       "      <td>6753</td>\n",
       "      <td>6706</td>\n",
       "      <td>1912</td>\n",
       "      <td>10</td>\n",
       "      <td>1899</td>\n",
       "      <td>2016-11-13 10:46:47.000</td>\n",
       "      <td>2016-10-28 02:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20276</th>\n",
       "      <td>GF_563</td>\n",
       "      <td>509</td>\n",
       "      <td>705</td>\n",
       "      <td>821</td>\n",
       "      <td>2016-11-12 13:46:57.000</td>\n",
       "      <td>2017-01-21 19:30:04.000</td>\n",
       "      <td>2826</td>\n",
       "      <td>4009</td>\n",
       "      <td>2912</td>\n",
       "      <td>1912</td>\n",
       "      <td>10</td>\n",
       "      <td>1451</td>\n",
       "      <td>2017-01-21 18:30:04.000</td>\n",
       "      <td>2017-01-18 01:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20277</th>\n",
       "      <td>GF_9107</td>\n",
       "      <td>682</td>\n",
       "      <td>213</td>\n",
       "      <td>5620</td>\n",
       "      <td>2016-11-12 13:47:01.000</td>\n",
       "      <td>2016-11-18 11:47:01.000</td>\n",
       "      <td>2089</td>\n",
       "      <td>6883</td>\n",
       "      <td>3607</td>\n",
       "      <td>1912</td>\n",
       "      <td>10</td>\n",
       "      <td>822</td>\n",
       "      <td>2016-11-14 12:47:01.000</td>\n",
       "      <td>2016-11-13 02:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20278</th>\n",
       "      <td>GF_5683</td>\n",
       "      <td>1061</td>\n",
       "      <td>212</td>\n",
       "      <td>4987</td>\n",
       "      <td>2016-11-12 13:48:30.000</td>\n",
       "      <td>2016-11-18 12:48:30.000</td>\n",
       "      <td>898</td>\n",
       "      <td>1814</td>\n",
       "      <td>6109</td>\n",
       "      <td>1912</td>\n",
       "      <td>10</td>\n",
       "      <td>1899</td>\n",
       "      <td>2016-11-12 10:48:30.000</td>\n",
       "      <td>2016-11-10 02:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20279 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        gift_id  gift_type  gift_category  gift_cluster  \\\n",
       "0      GF_11156         61            534          3942   \n",
       "1      GF_11157         61            534          3942   \n",
       "2      GF_15689        584            262             0   \n",
       "3      GF_11155         61            534          3942   \n",
       "4      GF_11158         61            534          3942   \n",
       "...         ...        ...            ...           ...   \n",
       "20274  GF_10269        105            704          6448   \n",
       "20275   GF_5854       1220            526           817   \n",
       "20276    GF_563        509            705           821   \n",
       "20277   GF_9107        682            213          5620   \n",
       "20278   GF_5683       1061            212          4987   \n",
       "\n",
       "                  instock_date        stock_update_date  lsg_1  lsg_2  lsg_3  \\\n",
       "0      2014-02-21 05:07:06.000  2016-11-09 15:49:51.000   3377   5221    504   \n",
       "1      2014-02-21 06:07:06.000  2016-11-11 13:49:51.000   3377   5221    504   \n",
       "2      2014-02-21 09:30:21.000  2016-03-24 14:46:18.000   5290   1579   3203   \n",
       "3      2014-02-22 05:07:06.000  2016-11-10 16:49:51.000   3377   5221    504   \n",
       "4      2014-02-22 07:07:06.000  2016-11-10 13:49:51.000   3377   5221    504   \n",
       "...                        ...                      ...    ...    ...    ...   \n",
       "20274  2016-11-12 13:46:42.000  2016-11-17 10:46:42.000   2055   6883    995   \n",
       "20275  2016-11-12 13:46:47.000  2016-11-18 13:46:47.000   8323   6753   6706   \n",
       "20276  2016-11-12 13:46:57.000  2017-01-21 19:30:04.000   2826   4009   2912   \n",
       "20277  2016-11-12 13:47:01.000  2016-11-18 11:47:01.000   2089   6883   3607   \n",
       "20278  2016-11-12 13:48:30.000  2016-11-18 12:48:30.000    898   1814   6109   \n",
       "\n",
       "       lsg_4  lsg_5  lsg_6                 uk_date1                 uk_date2  \\\n",
       "0       1912     10    554  2014-02-24 08:07:06.000  2014-02-24 07:07:06.000   \n",
       "1       1912     10    554  2014-02-22 07:07:06.000  2014-02-24 06:07:06.000   \n",
       "2       1912      9   1578  2016-01-26 00:04:45.000  2016-03-18 02:00:00.000   \n",
       "3       1912     10    554  2016-11-07 13:49:51.000  2016-11-06 04:00:00.000   \n",
       "4       1912      9    554  2016-11-07 15:49:51.000  2016-11-06 01:00:00.000   \n",
       "...      ...    ...    ...                      ...                      ...   \n",
       "20274   1912     10   1899  2016-11-14 14:46:42.000  2016-11-11 03:00:00.000   \n",
       "20275   1912     10   1899  2016-11-13 10:46:47.000  2016-10-28 02:00:00.000   \n",
       "20276   1912     10   1451  2017-01-21 18:30:04.000  2017-01-18 01:00:00.000   \n",
       "20277   1912     10    822  2016-11-14 12:47:01.000  2016-11-13 02:00:00.000   \n",
       "20278   1912     10   1899  2016-11-12 10:48:30.000  2016-11-10 02:00:00.000   \n",
       "\n",
       "       is_discounted  volumes   price  \n",
       "0                  0      NaN  175.54  \n",
       "1                  1      NaN   95.80  \n",
       "2                  1      NaN  107.35  \n",
       "3                  0      NaN  172.90  \n",
       "4                  1      NaN   77.72  \n",
       "...              ...      ...     ...  \n",
       "20274              0      NaN   57.68  \n",
       "20275              0      NaN  122.87  \n",
       "20276              0      NaN   47.14  \n",
       "20277              0      NaN   47.68  \n",
       "20278              0      NaN   52.81  \n",
       "\n",
       "[20279 rows x 17 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gift_id</th>\n",
       "      <th>gift_type</th>\n",
       "      <th>gift_category</th>\n",
       "      <th>gift_cluster</th>\n",
       "      <th>instock_date</th>\n",
       "      <th>stock_update_date</th>\n",
       "      <th>lsg_1</th>\n",
       "      <th>lsg_2</th>\n",
       "      <th>lsg_3</th>\n",
       "      <th>lsg_4</th>\n",
       "      <th>lsg_5</th>\n",
       "      <th>lsg_6</th>\n",
       "      <th>uk_date1</th>\n",
       "      <th>uk_date2</th>\n",
       "      <th>is_discounted</th>\n",
       "      <th>volumes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GF_2372</td>\n",
       "      <td>842</td>\n",
       "      <td>663</td>\n",
       "      <td>24</td>\n",
       "      <td>2016-11-12 13:49:12.000</td>\n",
       "      <td>2016-11-16 10:49:12.000</td>\n",
       "      <td>203</td>\n",
       "      <td>1334</td>\n",
       "      <td>4358</td>\n",
       "      <td>1912</td>\n",
       "      <td>10</td>\n",
       "      <td>1899</td>\n",
       "      <td>2016-11-16 12:49:12.000</td>\n",
       "      <td>2016-11-13 04:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GF_13040</td>\n",
       "      <td>407</td>\n",
       "      <td>534</td>\n",
       "      <td>754</td>\n",
       "      <td>2016-11-12 13:49:22.000</td>\n",
       "      <td>2016-11-17 14:49:22.000</td>\n",
       "      <td>4785</td>\n",
       "      <td>5940</td>\n",
       "      <td>2582</td>\n",
       "      <td>1912</td>\n",
       "      <td>10</td>\n",
       "      <td>1488</td>\n",
       "      <td>2016-11-12 14:49:22.000</td>\n",
       "      <td>2016-11-03 01:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GF_5754</td>\n",
       "      <td>631</td>\n",
       "      <td>433</td>\n",
       "      <td>6012</td>\n",
       "      <td>2016-11-12 13:49:23.000</td>\n",
       "      <td>2016-11-16 13:49:23.000</td>\n",
       "      <td>1812</td>\n",
       "      <td>5027</td>\n",
       "      <td>3427</td>\n",
       "      <td>1912</td>\n",
       "      <td>10</td>\n",
       "      <td>1913</td>\n",
       "      <td>2016-11-15 11:49:23.000</td>\n",
       "      <td>2016-11-01 05:00:00.000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GF_1417</td>\n",
       "      <td>992</td>\n",
       "      <td>433</td>\n",
       "      <td>6358</td>\n",
       "      <td>2016-11-12 13:49:24.000</td>\n",
       "      <td>2016-11-16 11:49:24.000</td>\n",
       "      <td>2002</td>\n",
       "      <td>6883</td>\n",
       "      <td>5537</td>\n",
       "      <td>1912</td>\n",
       "      <td>10</td>\n",
       "      <td>1734</td>\n",
       "      <td>2016-11-14 12:49:24.000</td>\n",
       "      <td>2016-11-04 04:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GF_23204</td>\n",
       "      <td>43</td>\n",
       "      <td>534</td>\n",
       "      <td>6123</td>\n",
       "      <td>2016-11-12 13:49:40.000</td>\n",
       "      <td>2016-11-18 11:49:40.000</td>\n",
       "      <td>1512</td>\n",
       "      <td>6883</td>\n",
       "      <td>610</td>\n",
       "      <td>1912</td>\n",
       "      <td>9</td>\n",
       "      <td>150</td>\n",
       "      <td>2016-11-14 10:49:40.000</td>\n",
       "      <td>2016-11-02 01:00:00.000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13514</th>\n",
       "      <td>GF_29169</td>\n",
       "      <td>31</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-07 20:51:34.000</td>\n",
       "      <td>2017-04-10 19:51:34.000</td>\n",
       "      <td>3252</td>\n",
       "      <td>3211</td>\n",
       "      <td>7565</td>\n",
       "      <td>1845</td>\n",
       "      <td>9</td>\n",
       "      <td>1899</td>\n",
       "      <td>2017-04-04 21:51:34.000</td>\n",
       "      <td>2017-03-30 07:00:59.623</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13515</th>\n",
       "      <td>GF_29165</td>\n",
       "      <td>31</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-07 22:51:34.000</td>\n",
       "      <td>2017-04-08 22:51:34.000</td>\n",
       "      <td>3252</td>\n",
       "      <td>3211</td>\n",
       "      <td>7565</td>\n",
       "      <td>1786</td>\n",
       "      <td>9</td>\n",
       "      <td>1899</td>\n",
       "      <td>2017-04-04 20:51:34.000</td>\n",
       "      <td>2017-04-02 09:00:59.623</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13516</th>\n",
       "      <td>GF_29168</td>\n",
       "      <td>31</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-07 22:51:34.000</td>\n",
       "      <td>2017-04-08 22:51:34.000</td>\n",
       "      <td>3252</td>\n",
       "      <td>3211</td>\n",
       "      <td>7565</td>\n",
       "      <td>1830</td>\n",
       "      <td>9</td>\n",
       "      <td>1899</td>\n",
       "      <td>2017-04-08 19:51:34.000</td>\n",
       "      <td>2017-03-31 06:00:59.623</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13517</th>\n",
       "      <td>GF_33797</td>\n",
       "      <td>280</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-15 18:55:17.000</td>\n",
       "      <td>2017-04-19 00:44:29.000</td>\n",
       "      <td>4198</td>\n",
       "      <td>3332</td>\n",
       "      <td>1805</td>\n",
       "      <td>1912</td>\n",
       "      <td>9</td>\n",
       "      <td>1899</td>\n",
       "      <td>2017-04-19 01:44:29.000</td>\n",
       "      <td>2017-04-15 18:03:15.352</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13518</th>\n",
       "      <td>GF_33798</td>\n",
       "      <td>1293</td>\n",
       "      <td>860</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-16 18:57:14.000</td>\n",
       "      <td>2017-04-18 21:41:27.000</td>\n",
       "      <td>8780</td>\n",
       "      <td>1393</td>\n",
       "      <td>7359</td>\n",
       "      <td>1912</td>\n",
       "      <td>9</td>\n",
       "      <td>1899</td>\n",
       "      <td>2017-04-16 00:41:27.000</td>\n",
       "      <td>2017-04-18 02:03:36.943</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13519 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        gift_id  gift_type  gift_category  gift_cluster  \\\n",
       "0       GF_2372        842            663            24   \n",
       "1      GF_13040        407            534           754   \n",
       "2       GF_5754        631            433          6012   \n",
       "3       GF_1417        992            433          6358   \n",
       "4      GF_23204         43            534          6123   \n",
       "...         ...        ...            ...           ...   \n",
       "13514  GF_29169         31             65             0   \n",
       "13515  GF_29165         31             65             0   \n",
       "13516  GF_29168         31             65             0   \n",
       "13517  GF_33797        280            184             0   \n",
       "13518  GF_33798       1293            860             0   \n",
       "\n",
       "                  instock_date        stock_update_date  lsg_1  lsg_2  lsg_3  \\\n",
       "0      2016-11-12 13:49:12.000  2016-11-16 10:49:12.000    203   1334   4358   \n",
       "1      2016-11-12 13:49:22.000  2016-11-17 14:49:22.000   4785   5940   2582   \n",
       "2      2016-11-12 13:49:23.000  2016-11-16 13:49:23.000   1812   5027   3427   \n",
       "3      2016-11-12 13:49:24.000  2016-11-16 11:49:24.000   2002   6883   5537   \n",
       "4      2016-11-12 13:49:40.000  2016-11-18 11:49:40.000   1512   6883    610   \n",
       "...                        ...                      ...    ...    ...    ...   \n",
       "13514  2017-04-07 20:51:34.000  2017-04-10 19:51:34.000   3252   3211   7565   \n",
       "13515  2017-04-07 22:51:34.000  2017-04-08 22:51:34.000   3252   3211   7565   \n",
       "13516  2017-04-07 22:51:34.000  2017-04-08 22:51:34.000   3252   3211   7565   \n",
       "13517  2017-04-15 18:55:17.000  2017-04-19 00:44:29.000   4198   3332   1805   \n",
       "13518  2017-04-16 18:57:14.000  2017-04-18 21:41:27.000   8780   1393   7359   \n",
       "\n",
       "       lsg_4  lsg_5  lsg_6                 uk_date1                 uk_date2  \\\n",
       "0       1912     10   1899  2016-11-16 12:49:12.000  2016-11-13 04:00:00.000   \n",
       "1       1912     10   1488  2016-11-12 14:49:22.000  2016-11-03 01:00:00.000   \n",
       "2       1912     10   1913  2016-11-15 11:49:23.000  2016-11-01 05:00:00.000   \n",
       "3       1912     10   1734  2016-11-14 12:49:24.000  2016-11-04 04:00:00.000   \n",
       "4       1912      9    150  2016-11-14 10:49:40.000  2016-11-02 01:00:00.000   \n",
       "...      ...    ...    ...                      ...                      ...   \n",
       "13514   1845      9   1899  2017-04-04 21:51:34.000  2017-03-30 07:00:59.623   \n",
       "13515   1786      9   1899  2017-04-04 20:51:34.000  2017-04-02 09:00:59.623   \n",
       "13516   1830      9   1899  2017-04-08 19:51:34.000  2017-03-31 06:00:59.623   \n",
       "13517   1912      9   1899  2017-04-19 01:44:29.000  2017-04-15 18:03:15.352   \n",
       "13518   1912      9   1899  2017-04-16 00:41:27.000  2017-04-18 02:03:36.943   \n",
       "\n",
       "       is_discounted  volumes  \n",
       "0                  0      NaN  \n",
       "1                  0      NaN  \n",
       "2                  1      NaN  \n",
       "3                  0      NaN  \n",
       "4                  1      NaN  \n",
       "...              ...      ...  \n",
       "13514              0     27.0  \n",
       "13515              0     23.0  \n",
       "13516              0     23.0  \n",
       "13517              0      NaN  \n",
       "13518              0      NaN  \n",
       "\n",
       "[13519 rows x 16 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gift_type</th>\n",
       "      <th>gift_category</th>\n",
       "      <th>gift_cluster</th>\n",
       "      <th>lsg_1</th>\n",
       "      <th>lsg_2</th>\n",
       "      <th>lsg_3</th>\n",
       "      <th>lsg_4</th>\n",
       "      <th>lsg_5</th>\n",
       "      <th>lsg_6</th>\n",
       "      <th>is_discounted</th>\n",
       "      <th>volumes</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20279.000000</td>\n",
       "      <td>20279.000000</td>\n",
       "      <td>20279.000000</td>\n",
       "      <td>20279.000000</td>\n",
       "      <td>20279.000000</td>\n",
       "      <td>20279.000000</td>\n",
       "      <td>20279.000000</td>\n",
       "      <td>20279.000000</td>\n",
       "      <td>20279.000000</td>\n",
       "      <td>20279.000000</td>\n",
       "      <td>7323.000000</td>\n",
       "      <td>20279.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>739.554662</td>\n",
       "      <td>394.171557</td>\n",
       "      <td>3303.358548</td>\n",
       "      <td>5314.595345</td>\n",
       "      <td>4187.653928</td>\n",
       "      <td>4866.945510</td>\n",
       "      <td>1679.152226</td>\n",
       "      <td>8.652695</td>\n",
       "      <td>1265.898171</td>\n",
       "      <td>0.229646</td>\n",
       "      <td>15.515363</td>\n",
       "      <td>143.404411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>389.216989</td>\n",
       "      <td>235.077769</td>\n",
       "      <td>2541.082549</td>\n",
       "      <td>2703.317282</td>\n",
       "      <td>2274.875522</td>\n",
       "      <td>2713.856392</td>\n",
       "      <td>485.699119</td>\n",
       "      <td>2.349388</td>\n",
       "      <td>697.838495</td>\n",
       "      <td>0.420616</td>\n",
       "      <td>7.579669</td>\n",
       "      <td>267.281159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>403.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>587.000000</td>\n",
       "      <td>3311.000000</td>\n",
       "      <td>2251.000000</td>\n",
       "      <td>2548.000000</td>\n",
       "      <td>1801.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>577.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>45.645000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>825.000000</td>\n",
       "      <td>433.000000</td>\n",
       "      <td>3231.000000</td>\n",
       "      <td>5520.000000</td>\n",
       "      <td>4246.000000</td>\n",
       "      <td>4839.000000</td>\n",
       "      <td>1912.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1616.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>75.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1032.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>5787.000000</td>\n",
       "      <td>7535.000000</td>\n",
       "      <td>6504.500000</td>\n",
       "      <td>7387.000000</td>\n",
       "      <td>1912.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1899.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>126.845000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1360.000000</td>\n",
       "      <td>893.000000</td>\n",
       "      <td>7567.000000</td>\n",
       "      <td>9979.000000</td>\n",
       "      <td>7604.000000</td>\n",
       "      <td>9493.000000</td>\n",
       "      <td>2056.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>7010.270000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          gift_type  gift_category  gift_cluster         lsg_1         lsg_2  \\\n",
       "count  20279.000000   20279.000000  20279.000000  20279.000000  20279.000000   \n",
       "mean     739.554662     394.171557   3303.358548   5314.595345   4187.653928   \n",
       "std      389.216989     235.077769   2541.082549   2703.317282   2274.875522   \n",
       "min        1.000000       1.000000      0.000000      0.000000      0.000000   \n",
       "25%      403.000000     188.000000    587.000000   3311.000000   2251.000000   \n",
       "50%      825.000000     433.000000   3231.000000   5520.000000   4246.000000   \n",
       "75%     1032.000000     534.000000   5787.000000   7535.000000   6504.500000   \n",
       "max     1360.000000     893.000000   7567.000000   9979.000000   7604.000000   \n",
       "\n",
       "              lsg_3         lsg_4         lsg_5         lsg_6  is_discounted  \\\n",
       "count  20279.000000  20279.000000  20279.000000  20279.000000   20279.000000   \n",
       "mean    4866.945510   1679.152226      8.652695   1265.898171       0.229646   \n",
       "std     2713.856392    485.699119      2.349388    697.838495       0.420616   \n",
       "min        0.000000      3.000000      0.000000      0.000000       0.000000   \n",
       "25%     2548.000000   1801.000000      9.000000    577.500000       0.000000   \n",
       "50%     4839.000000   1912.000000      9.000000   1616.000000       0.000000   \n",
       "75%     7387.000000   1912.000000     10.000000   1899.000000       0.000000   \n",
       "max     9493.000000   2056.000000     10.000000   2065.000000       1.000000   \n",
       "\n",
       "           volumes         price  \n",
       "count  7323.000000  20279.000000  \n",
       "mean     15.515363    143.404411  \n",
       "std       7.579669    267.281159  \n",
       "min       5.000000      0.010000  \n",
       "25%       9.000000     45.645000  \n",
       "50%      13.000000     75.600000  \n",
       "75%      24.000000    126.845000  \n",
       "max      29.000000   7010.270000  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missingcheck(data):\n",
    "    total = data.isnull().sum().sort_values(ascending=False)\n",
    "    percent_1 = data.isnull().sum()/data.isnull().count()*100\n",
    "    percent_2 = (np.round(percent_1, 1)).sort_values(ascending=False)\n",
    "    missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%']) #ptr\n",
    "    return missing_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>volumes</th>\n",
       "      <td>12956</td>\n",
       "      <td>63.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsg_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gift_type</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gift_category</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gift_cluster</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instock_date</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stock_update_date</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsg_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsg_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsg_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsg_5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsg_6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uk_date1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uk_date2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_discounted</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gift_id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Total     %\n",
       "volumes            12956  63.9\n",
       "price                  0   0.0\n",
       "lsg_2                  0   0.0\n",
       "gift_type              0   0.0\n",
       "gift_category          0   0.0\n",
       "gift_cluster           0   0.0\n",
       "instock_date           0   0.0\n",
       "stock_update_date      0   0.0\n",
       "lsg_1                  0   0.0\n",
       "lsg_3                  0   0.0\n",
       "lsg_4                  0   0.0\n",
       "lsg_5                  0   0.0\n",
       "lsg_6                  0   0.0\n",
       "uk_date1               0   0.0\n",
       "uk_date2               0   0.0\n",
       "is_discounted          0   0.0\n",
       "gift_id                0   0.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missingcheck(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>volumes</th>\n",
       "      <td>2352</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_discounted</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uk_date2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uk_date1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsg_6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsg_5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsg_4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsg_3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsg_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsg_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stock_update_date</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instock_date</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gift_cluster</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gift_category</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gift_type</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gift_id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Total     %\n",
       "volumes             2352  17.4\n",
       "is_discounted          0   0.0\n",
       "uk_date2               0   0.0\n",
       "uk_date1               0   0.0\n",
       "lsg_6                  0   0.0\n",
       "lsg_5                  0   0.0\n",
       "lsg_4                  0   0.0\n",
       "lsg_3                  0   0.0\n",
       "lsg_2                  0   0.0\n",
       "lsg_1                  0   0.0\n",
       "stock_update_date      0   0.0\n",
       "instock_date           0   0.0\n",
       "gift_cluster           0   0.0\n",
       "gift_category          0   0.0\n",
       "gift_type              0   0.0\n",
       "gift_id                0   0.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missingcheck(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dff = df.drop( ['volumes'],axis =1)\n",
    "dff = df.fillna(0)\n",
    "tff = test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['instock_date'] = pd.to_datetime(dff['instock_date'] ,errors='coerce')\n",
    "dff['justinstock_date'] = dff['instock_date'].dt.date\n",
    "\n",
    "\n",
    "tff['instock_date'] = pd.to_datetime(tff['instock_date'] ,errors='coerce')\n",
    "tff['justinstock_date'] = tff['instock_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['stock_update_date'] = pd.to_datetime(dff['stock_update_date'] ,errors='coerce')\n",
    "dff['juststock_update_date'] = dff['stock_update_date'].dt.date\n",
    "\n",
    "tff['stock_update_date'] = pd.to_datetime(tff['stock_update_date'] ,errors='coerce')\n",
    "tff['juststock_update_date'] = tff['stock_update_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['uk_date1'] = pd.to_datetime(dff['uk_date1'] ,errors='coerce')\n",
    "dff['justuk_date1'] = dff['uk_date1'].dt.date\n",
    "\n",
    "tff['uk_date1'] = pd.to_datetime(tff['uk_date1'] ,errors='coerce')\n",
    "tff['justuk_date1'] = tff['uk_date1'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['uk_date2'] = pd.to_datetime(dff['uk_date2'] ,errors='coerce')\n",
    "dff['justuk_date2'] = dff['uk_date2'].dt.date\n",
    "\n",
    "tff['uk_date2'] = pd.to_datetime(tff['uk_date2'] ,errors='coerce')\n",
    "tff['justuk_date2'] = tff['uk_date2'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no of days gift was in stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['DaysStockUpdate'] = (dff['stock_update_date']- dff['instock_date']).dt.days\n",
    "\n",
    "\n",
    "tff['DaysStockUpdate'] = (tff['stock_update_date']- tff['instock_date']).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no of days between order1 and order2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['buyer12diff'] = (dff['uk_date1']-dff['uk_date2']).dt.days\n",
    "dff['buyer12diff'] = np.absolute(dff['buyer12diff'])\n",
    "\n",
    "\n",
    "\n",
    "tff['buyer12diff'] = (tff['uk_date1']-tff['uk_date2']).dt.days\n",
    "tff['buyer12diff'] = np.absolute(tff['buyer12diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at order1 time was gift in stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['buy1buytime'] = (dff['uk_date1'] -dff['instock_date']).dt.days\n",
    "\n",
    "tff['buy1buytime'] = (tff['uk_date1'] -tff['instock_date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2658     -5\n",
       "1107     -5\n",
       "1259     -5\n",
       "1260     -5\n",
       "1269     -5\n",
       "       ... \n",
       "967     137\n",
       "941     142\n",
       "936     143\n",
       "1097    144\n",
       "769     145\n",
       "Name: buy1buytime, Length: 13519, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff['buy1buytime'].sort_values()\n",
    "\n",
    "tff['buy1buytime'].sort_values()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order 2 in stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['buy2buytime'] = (dff['uk_date2'] -dff['instock_date']).dt.days\n",
    "\n",
    "\n",
    "tff['buy2buytime'] = (tff['uk_date2'] -tff['instock_date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2741   -668\n",
       "2943   -664\n",
       "3014   -663\n",
       "2017   -661\n",
       "1747   -660\n",
       "       ... \n",
       "1097    134\n",
       "811     134\n",
       "46      137\n",
       "936     137\n",
       "769     138\n",
       "Name: buy2buytime, Length: 13519, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff['buy2buytime'].sort_values()\n",
    "\n",
    "tff['buy2buytime'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stockupdate date differece "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['stockupdatediff1'] = (dff['stock_update_date'] - dff['uk_date1']).dt.days\n",
    "\n",
    "\n",
    "tff['stockupdatediff1'] = (tff['stock_update_date'] - tff['uk_date1']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['stockupdatediff2'] = (dff['stock_update_date'] - dff['uk_date2']).dt.days\n",
    "\n",
    "\n",
    "tff['stockupdatediff2'] = (tff['stock_update_date'] - tff['uk_date2']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_datepart(df, fldname, drop=True):\n",
    "    fld = df[fldname]\n",
    "    if not np.issubdtype(fld.dtype, np.datetime64):\n",
    "        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n",
    "    targ_pre = re.sub('[Dd]ate$', '', fldname)\n",
    "    \n",
    "#     for n in ('Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear',\n",
    "#             'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start'):\n",
    "    \n",
    "    for n in ('Year', 'Month', 'Week', 'Day','Hour', 'Dayofweek', 'Dayofyear',\n",
    "            'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start'):\n",
    "        df[targ_pre+n] = getattr(fld.dt,n.lower())\n",
    "    df[targ_pre+'Elapsed'] = fld.astype(np.int64) // 10**9\n",
    "    if drop: df.drop(fldname, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_datepart(dff, 'instock_date',drop = False)\n",
    "\n",
    "add_datepart(tff, 'instock_date',drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_datepart(dff, 'stock_update_date',drop =False)\n",
    "\n",
    "\n",
    "add_datepart(tff, 'stock_update_date',drop =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_datepart(dff, 'uk_date1', drop=False)\n",
    "\n",
    "\n",
    "add_datepart(tff, 'uk_date1', drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_datepart(dff, 'uk_date2', drop= False)\n",
    "\n",
    "\n",
    "add_datepart(tff, 'uk_date2', drop= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-04-16 18:57:14')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff['instock_date'].max()\n",
    "\n",
    "tff['instock_date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-04-19 00:44:29')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff['stock_update_date'].max()\n",
    "\n",
    "tff['stock_update_date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-04-18 02:03:36.943000')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff['uk_date2'].max()\n",
    "\n",
    "tff['uk_date2'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "### was it a holiday or not instockdate, stockupdateday,ukdate1,ukdate2\n",
    "time = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = dff['instock_date'].min()\n",
    "\n",
    "# end = dff['stock_update_date'].max()\n",
    "\n",
    "# time['date'] = pd.date_range(start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uk_holidays=[]\n",
    "# for holiday in holidays.UK(years=[2014,2015,2016]).items():\n",
    "#     uk_holidays.append(str(holiday[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#uk_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dff['Isholidayinstock']= [ 1 if str(val).split()[0] in uk_holidays else 0 for val in dff['instock_date']]\n",
    "# dff['Isholidaystockupdate']= [ 1 if str(val).split()[0] in uk_holidays else 0 for val in dff['stock_update_date']]\n",
    "# dff['IsholidayUkdate1']= [ 1 if str(val).split()[0] in uk_holidays else 0 for val in dff['uk_date1']]\n",
    "# dff['IsholidayUkdate2']= [ 1 if str(val).split()[0] in uk_holidays else 0 for val in dff['uk_date2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### grace period dates ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_graceholiday=[]\n",
    "for holiday in holidays.UK(years=[2014,2015,2016]).items():\n",
    "    uk_graceholiday.append(holiday[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "graceondate=[]\n",
    "for i in uk_graceholiday:\n",
    "    twodayago = i - timedelta(days = 3)\n",
    "    twodayafter = i + timedelta(days = 3)\n",
    "    for date in pd.date_range(twodayago,twodayafter):\n",
    "        graceondate.append((str(date).split()[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_graceperiod = list(set(graceondate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['Isholidayinstockgrceperiod']= [ 1 if str(val).split()[0] in uk_graceperiod else 0 for val in dff['instock_date']]\n",
    "dff['Isholidaystock_update_dategrceperiod']= [ 1 if str(val).split()[0] in uk_graceperiod else 0 for val in dff['stock_update_date']]\n",
    "dff['IsholidayUk_date1grceperiod']= [ 1 if str(val).split()[0] in uk_graceperiod else 0 for val in dff['uk_date1']]\n",
    "dff['IsholidayUk_date2grceperiod']= [ 1 if str(val).split()[0] in uk_graceperiod else 0 for val in dff['uk_date2']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tff['Isholidayinstockgrceperiod']= [ 1 if str(val).split()[0] in uk_graceperiod else 0 for val in tff['instock_date']]\n",
    "tff['Isholidaystock_update_dategrceperiod']= [ 1 if str(val).split()[0] in uk_graceperiod else 0 for val in tff['stock_update_date']]\n",
    "tff['IsholidayUk_date1grceperiod']= [ 1 if str(val).split()[0] in uk_graceperiod else 0 for val in tff['uk_date1']]\n",
    "tff['IsholidayUk_date2grceperiod']= [ 1 if str(val).split()[0] in uk_graceperiod else 0 for val in tff['uk_date2']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interaction variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createIntercations(data,cat_features):\n",
    "    import itertools\n",
    "    print(f\"Creating features on {cat_features}, with combination 2 for training data /n\")\n",
    "    interactionstrain = pd.DataFrame(index=data.index)\n",
    "    \n",
    "    for col1 ,col2 in  itertools.combinations(cat_features,2):   \n",
    "        newcolname = col1 + \"_\" + col2 #+\"_\" + col3\n",
    "        new_values = data[col1].map(str) + \"_\" + data[col2].map(str) # + \"_\" + data[col3].map(str)\n",
    "        interactionstrain[newcolname] = new_values\n",
    "\n",
    "    print(interactionstrain)\n",
    "    data_df = data.join(interactionstrain)\n",
    "    \n",
    "    \n",
    "    print(data_df.shape)\n",
    "    \n",
    "    \n",
    "    return data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createIntercations2(data,cat_features):\n",
    "    import itertools\n",
    "    print(f\"Creating features on {cat_features}, with combination 3 for training data /n\")\n",
    "    interactionstrain = pd.DataFrame(index=data.index)\n",
    "    \n",
    "    for col1 ,col2,col3 in  itertools.combinations(cat_features,3):   \n",
    "        newcolname = col1 + \"_\" + col2 +\"_\" + col3\n",
    "        new_values = data[col1].map(str) + \"_\" + data[col2].map(str)  + \"_\" + data[col3].map(str)\n",
    "        interactionstrain[newcolname] = new_values\n",
    "\n",
    "    print(interactionstrain)\n",
    "    data_df = data.join(interactionstrain)\n",
    "    \n",
    "    \n",
    "    print(data_df.shape)\n",
    "    \n",
    "    \n",
    "    return data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def createlogfestures(data,features):\n",
    "  \n",
    "#      cols = features\n",
    "#      interactionstrain = pd.DataFrame(index=data.index)\n",
    "        \n",
    "#      for col  in cols:   \n",
    "#             newcolname = col + \"_log\"   \n",
    "#             new_values = np.log1p(data[col])\n",
    "#             interactionstrain[newcolname] = new_values\n",
    "\n",
    "  \n",
    "\n",
    "#      data_df = data.join(interactionstrain)\n",
    "  \n",
    "#      print(data_df.shape)\n",
    "\n",
    "\n",
    "#      return data_df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def createsqrtfeatures(train,test,features):\n",
    "    \n",
    "\n",
    "#   cols = features\n",
    "#   interactionstrain = pd.DataFrame(index=train.index)\n",
    "#   interactionstest = pd.DataFrame(index=test.index)\n",
    "  \n",
    "#   for col  in cols:   \n",
    "#         newcolname = col + \"_sqrt\"   \n",
    "#         new_values = np.sqrt(train[col])\n",
    "#         interactionstrain[newcolname] = new_values\n",
    "\n",
    "#   for col  in cols:   \n",
    "#         newcolname = col + \"_sqrt\"   \n",
    "#         new_values = np.sqrt(test[col])\n",
    "#         interactionstest[newcolname] = new_values\n",
    "\n",
    "\n",
    "#   train_df = train.join(interactionstrain)\n",
    "#   test_df = test.join(interactionstest)\n",
    "\n",
    "#   print(train_df.shape,test_df.shape)\n",
    "\n",
    "\n",
    "#   return train_df ,test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating features on ['gift_type', 'gift_category', 'gift_cluster'], with combination 2 for training data /n\n",
      "      gift_type_gift_category gift_type_gift_cluster  \\\n",
      "0                      61_534                61_3942   \n",
      "1                      61_534                61_3942   \n",
      "2                     584_262                  584_0   \n",
      "3                      61_534                61_3942   \n",
      "4                      61_534                61_3942   \n",
      "...                       ...                    ...   \n",
      "20274                 105_704               105_6448   \n",
      "20275                1220_526               1220_817   \n",
      "20276                 509_705                509_821   \n",
      "20277                 682_213               682_5620   \n",
      "20278                1061_212              1061_4987   \n",
      "\n",
      "      gift_category_gift_cluster  \n",
      "0                       534_3942  \n",
      "1                       534_3942  \n",
      "2                          262_0  \n",
      "3                       534_3942  \n",
      "4                       534_3942  \n",
      "...                          ...  \n",
      "20274                   704_6448  \n",
      "20275                    526_817  \n",
      "20276                    705_821  \n",
      "20277                   213_5620  \n",
      "20278                   212_4987  \n",
      "\n",
      "[20279 rows x 3 columns]\n",
      "(20279, 90)\n",
      "Creating features on ['gift_type', 'gift_category', 'gift_cluster'], with combination 2 for training data /n\n",
      "      gift_type_gift_category gift_type_gift_cluster  \\\n",
      "0                     842_663                 842_24   \n",
      "1                     407_534                407_754   \n",
      "2                     631_433               631_6012   \n",
      "3                     992_433               992_6358   \n",
      "4                      43_534                43_6123   \n",
      "...                       ...                    ...   \n",
      "13514                   31_65                   31_0   \n",
      "13515                   31_65                   31_0   \n",
      "13516                   31_65                   31_0   \n",
      "13517                 280_184                  280_0   \n",
      "13518                1293_860                 1293_0   \n",
      "\n",
      "      gift_category_gift_cluster  \n",
      "0                         663_24  \n",
      "1                        534_754  \n",
      "2                       433_6012  \n",
      "3                       433_6358  \n",
      "4                       534_6123  \n",
      "...                          ...  \n",
      "13514                       65_0  \n",
      "13515                       65_0  \n",
      "13516                       65_0  \n",
      "13517                      184_0  \n",
      "13518                      860_0  \n",
      "\n",
      "[13519 rows x 3 columns]\n",
      "(13519, 89)\n"
     ]
    }
   ],
   "source": [
    "interactiondff1 = createIntercations(dff,['gift_type','gift_category','gift_cluster'])\n",
    "\n",
    "interactiontff1 = createIntercations(tff,['gift_type','gift_category','gift_cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating features on ['gift_type', 'gift_category', 'gift_cluster'], with combination 3 for training data /n\n",
      "      gift_type_gift_category_gift_cluster\n",
      "0                              61_534_3942\n",
      "1                              61_534_3942\n",
      "2                                584_262_0\n",
      "3                              61_534_3942\n",
      "4                              61_534_3942\n",
      "...                                    ...\n",
      "20274                         105_704_6448\n",
      "20275                         1220_526_817\n",
      "20276                          509_705_821\n",
      "20277                         682_213_5620\n",
      "20278                        1061_212_4987\n",
      "\n",
      "[20279 rows x 1 columns]\n",
      "(20279, 91)\n",
      "Creating features on ['gift_type', 'gift_category', 'gift_cluster'], with combination 3 for training data /n\n",
      "      gift_type_gift_category_gift_cluster\n",
      "0                               842_663_24\n",
      "1                              407_534_754\n",
      "2                             631_433_6012\n",
      "3                             992_433_6358\n",
      "4                              43_534_6123\n",
      "...                                    ...\n",
      "13514                              31_65_0\n",
      "13515                              31_65_0\n",
      "13516                              31_65_0\n",
      "13517                            280_184_0\n",
      "13518                           1293_860_0\n",
      "\n",
      "[13519 rows x 1 columns]\n",
      "(13519, 90)\n"
     ]
    }
   ],
   "source": [
    "interactiondff2 = createIntercations2(interactiondff1,['gift_type','gift_category','gift_cluster'])\n",
    "\n",
    "\n",
    "interactiontff2 = createIntercations2(interactiontff1,['gift_type','gift_category','gift_cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gift_id</th>\n",
       "      <th>gift_type</th>\n",
       "      <th>gift_category</th>\n",
       "      <th>gift_cluster</th>\n",
       "      <th>instock_date</th>\n",
       "      <th>stock_update_date</th>\n",
       "      <th>lsg_1</th>\n",
       "      <th>lsg_2</th>\n",
       "      <th>lsg_3</th>\n",
       "      <th>lsg_4</th>\n",
       "      <th>...</th>\n",
       "      <th>uk_date2Is_year_start</th>\n",
       "      <th>uk_date2Elapsed</th>\n",
       "      <th>Isholidayinstockgrceperiod</th>\n",
       "      <th>Isholidaystock_update_dategrceperiod</th>\n",
       "      <th>IsholidayUk_date1grceperiod</th>\n",
       "      <th>IsholidayUk_date2grceperiod</th>\n",
       "      <th>gift_type_gift_category</th>\n",
       "      <th>gift_type_gift_cluster</th>\n",
       "      <th>gift_category_gift_cluster</th>\n",
       "      <th>gift_type_gift_category_gift_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GF_2372</td>\n",
       "      <td>842</td>\n",
       "      <td>663</td>\n",
       "      <td>24</td>\n",
       "      <td>2016-11-12 13:49:12</td>\n",
       "      <td>2016-11-16 10:49:12</td>\n",
       "      <td>203</td>\n",
       "      <td>1334</td>\n",
       "      <td>4358</td>\n",
       "      <td>1912</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1479009600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>842_663</td>\n",
       "      <td>842_24</td>\n",
       "      <td>663_24</td>\n",
       "      <td>842_663_24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GF_13040</td>\n",
       "      <td>407</td>\n",
       "      <td>534</td>\n",
       "      <td>754</td>\n",
       "      <td>2016-11-12 13:49:22</td>\n",
       "      <td>2016-11-17 14:49:22</td>\n",
       "      <td>4785</td>\n",
       "      <td>5940</td>\n",
       "      <td>2582</td>\n",
       "      <td>1912</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1478134800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>407_534</td>\n",
       "      <td>407_754</td>\n",
       "      <td>534_754</td>\n",
       "      <td>407_534_754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GF_5754</td>\n",
       "      <td>631</td>\n",
       "      <td>433</td>\n",
       "      <td>6012</td>\n",
       "      <td>2016-11-12 13:49:23</td>\n",
       "      <td>2016-11-16 13:49:23</td>\n",
       "      <td>1812</td>\n",
       "      <td>5027</td>\n",
       "      <td>3427</td>\n",
       "      <td>1912</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1477976400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>631_433</td>\n",
       "      <td>631_6012</td>\n",
       "      <td>433_6012</td>\n",
       "      <td>631_433_6012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GF_1417</td>\n",
       "      <td>992</td>\n",
       "      <td>433</td>\n",
       "      <td>6358</td>\n",
       "      <td>2016-11-12 13:49:24</td>\n",
       "      <td>2016-11-16 11:49:24</td>\n",
       "      <td>2002</td>\n",
       "      <td>6883</td>\n",
       "      <td>5537</td>\n",
       "      <td>1912</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1478232000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>992_433</td>\n",
       "      <td>992_6358</td>\n",
       "      <td>433_6358</td>\n",
       "      <td>992_433_6358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GF_23204</td>\n",
       "      <td>43</td>\n",
       "      <td>534</td>\n",
       "      <td>6123</td>\n",
       "      <td>2016-11-12 13:49:40</td>\n",
       "      <td>2016-11-18 11:49:40</td>\n",
       "      <td>1512</td>\n",
       "      <td>6883</td>\n",
       "      <td>610</td>\n",
       "      <td>1912</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1478048400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43_534</td>\n",
       "      <td>43_6123</td>\n",
       "      <td>534_6123</td>\n",
       "      <td>43_534_6123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    gift_id  gift_type  gift_category  gift_cluster        instock_date  \\\n",
       "0   GF_2372        842            663            24 2016-11-12 13:49:12   \n",
       "1  GF_13040        407            534           754 2016-11-12 13:49:22   \n",
       "2   GF_5754        631            433          6012 2016-11-12 13:49:23   \n",
       "3   GF_1417        992            433          6358 2016-11-12 13:49:24   \n",
       "4  GF_23204         43            534          6123 2016-11-12 13:49:40   \n",
       "\n",
       "    stock_update_date  lsg_1  lsg_2  lsg_3  lsg_4  ...  uk_date2Is_year_start  \\\n",
       "0 2016-11-16 10:49:12    203   1334   4358   1912  ...                  False   \n",
       "1 2016-11-17 14:49:22   4785   5940   2582   1912  ...                  False   \n",
       "2 2016-11-16 13:49:23   1812   5027   3427   1912  ...                  False   \n",
       "3 2016-11-16 11:49:24   2002   6883   5537   1912  ...                  False   \n",
       "4 2016-11-18 11:49:40   1512   6883    610   1912  ...                  False   \n",
       "\n",
       "   uk_date2Elapsed Isholidayinstockgrceperiod  \\\n",
       "0       1479009600                          0   \n",
       "1       1478134800                          0   \n",
       "2       1477976400                          0   \n",
       "3       1478232000                          0   \n",
       "4       1478048400                          0   \n",
       "\n",
       "  Isholidaystock_update_dategrceperiod  IsholidayUk_date1grceperiod  \\\n",
       "0                                    0                            0   \n",
       "1                                    0                            0   \n",
       "2                                    0                            0   \n",
       "3                                    0                            0   \n",
       "4                                    0                            0   \n",
       "\n",
       "   IsholidayUk_date2grceperiod gift_type_gift_category gift_type_gift_cluster  \\\n",
       "0                            0                 842_663                 842_24   \n",
       "1                            0                 407_534                407_754   \n",
       "2                            0                 631_433               631_6012   \n",
       "3                            0                 992_433               992_6358   \n",
       "4                            0                  43_534                43_6123   \n",
       "\n",
       "  gift_category_gift_cluster gift_type_gift_category_gift_cluster  \n",
       "0                     663_24                           842_663_24  \n",
       "1                    534_754                          407_534_754  \n",
       "2                   433_6012                         631_433_6012  \n",
       "3                   433_6358                         992_433_6358  \n",
       "4                   534_6123                          43_534_6123  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactiondff2.head()\n",
    "\n",
    "\n",
    "interactiontff2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# interactiondff2.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating features on ['lsg_1', 'lsg_2', 'lsg_3', 'lsg_4', 'lsg_5', 'lsg_6'], with combination 2 for training data /n\n",
      "      lsg_1_lsg_2 lsg_1_lsg_3 lsg_1_lsg_4 lsg_1_lsg_5 lsg_1_lsg_6 lsg_2_lsg_3  \\\n",
      "0       3377_5221    3377_504   3377_1912     3377_10    3377_554    5221_504   \n",
      "1       3377_5221    3377_504   3377_1912     3377_10    3377_554    5221_504   \n",
      "2       5290_1579   5290_3203   5290_1912      5290_9   5290_1578   1579_3203   \n",
      "3       3377_5221    3377_504   3377_1912     3377_10    3377_554    5221_504   \n",
      "4       3377_5221    3377_504   3377_1912      3377_9    3377_554    5221_504   \n",
      "...           ...         ...         ...         ...         ...         ...   \n",
      "20274   2055_6883    2055_995   2055_1912     2055_10   2055_1899    6883_995   \n",
      "20275   8323_6753   8323_6706   8323_1912     8323_10   8323_1899   6753_6706   \n",
      "20276   2826_4009   2826_2912   2826_1912     2826_10   2826_1451   4009_2912   \n",
      "20277   2089_6883   2089_3607   2089_1912     2089_10    2089_822   6883_3607   \n",
      "20278    898_1814    898_6109    898_1912      898_10    898_1899   1814_6109   \n",
      "\n",
      "      lsg_2_lsg_4 lsg_2_lsg_5 lsg_2_lsg_6 lsg_3_lsg_4 lsg_3_lsg_5 lsg_3_lsg_6  \\\n",
      "0       5221_1912     5221_10    5221_554    504_1912      504_10     504_554   \n",
      "1       5221_1912     5221_10    5221_554    504_1912      504_10     504_554   \n",
      "2       1579_1912      1579_9   1579_1578   3203_1912      3203_9   3203_1578   \n",
      "3       5221_1912     5221_10    5221_554    504_1912      504_10     504_554   \n",
      "4       5221_1912      5221_9    5221_554    504_1912       504_9     504_554   \n",
      "...           ...         ...         ...         ...         ...         ...   \n",
      "20274   6883_1912     6883_10   6883_1899    995_1912      995_10    995_1899   \n",
      "20275   6753_1912     6753_10   6753_1899   6706_1912     6706_10   6706_1899   \n",
      "20276   4009_1912     4009_10   4009_1451   2912_1912     2912_10   2912_1451   \n",
      "20277   6883_1912     6883_10    6883_822   3607_1912     3607_10    3607_822   \n",
      "20278   1814_1912     1814_10   1814_1899   6109_1912     6109_10   6109_1899   \n",
      "\n",
      "      lsg_4_lsg_5 lsg_4_lsg_6 lsg_5_lsg_6  \n",
      "0         1912_10    1912_554      10_554  \n",
      "1         1912_10    1912_554      10_554  \n",
      "2          1912_9   1912_1578      9_1578  \n",
      "3         1912_10    1912_554      10_554  \n",
      "4          1912_9    1912_554       9_554  \n",
      "...           ...         ...         ...  \n",
      "20274     1912_10   1912_1899     10_1899  \n",
      "20275     1912_10   1912_1899     10_1899  \n",
      "20276     1912_10   1912_1451     10_1451  \n",
      "20277     1912_10    1912_822      10_822  \n",
      "20278     1912_10   1912_1899     10_1899  \n",
      "\n",
      "[20279 rows x 15 columns]\n",
      "(20279, 106)\n",
      "Creating features on ['lsg_1', 'lsg_2', 'lsg_3', 'lsg_4', 'lsg_5', 'lsg_6'], with combination 2 for training data /n\n",
      "      lsg_1_lsg_2 lsg_1_lsg_3 lsg_1_lsg_4 lsg_1_lsg_5 lsg_1_lsg_6 lsg_2_lsg_3  \\\n",
      "0        203_1334    203_4358    203_1912      203_10    203_1899   1334_4358   \n",
      "1       4785_5940   4785_2582   4785_1912     4785_10   4785_1488   5940_2582   \n",
      "2       1812_5027   1812_3427   1812_1912     1812_10   1812_1913   5027_3427   \n",
      "3       2002_6883   2002_5537   2002_1912     2002_10   2002_1734   6883_5537   \n",
      "4       1512_6883    1512_610   1512_1912      1512_9    1512_150    6883_610   \n",
      "...           ...         ...         ...         ...         ...         ...   \n",
      "13514   3252_3211   3252_7565   3252_1845      3252_9   3252_1899   3211_7565   \n",
      "13515   3252_3211   3252_7565   3252_1786      3252_9   3252_1899   3211_7565   \n",
      "13516   3252_3211   3252_7565   3252_1830      3252_9   3252_1899   3211_7565   \n",
      "13517   4198_3332   4198_1805   4198_1912      4198_9   4198_1899   3332_1805   \n",
      "13518   8780_1393   8780_7359   8780_1912      8780_9   8780_1899   1393_7359   \n",
      "\n",
      "      lsg_2_lsg_4 lsg_2_lsg_5 lsg_2_lsg_6 lsg_3_lsg_4 lsg_3_lsg_5 lsg_3_lsg_6  \\\n",
      "0       1334_1912     1334_10   1334_1899   4358_1912     4358_10   4358_1899   \n",
      "1       5940_1912     5940_10   5940_1488   2582_1912     2582_10   2582_1488   \n",
      "2       5027_1912     5027_10   5027_1913   3427_1912     3427_10   3427_1913   \n",
      "3       6883_1912     6883_10   6883_1734   5537_1912     5537_10   5537_1734   \n",
      "4       6883_1912      6883_9    6883_150    610_1912       610_9     610_150   \n",
      "...           ...         ...         ...         ...         ...         ...   \n",
      "13514   3211_1845      3211_9   3211_1899   7565_1845      7565_9   7565_1899   \n",
      "13515   3211_1786      3211_9   3211_1899   7565_1786      7565_9   7565_1899   \n",
      "13516   3211_1830      3211_9   3211_1899   7565_1830      7565_9   7565_1899   \n",
      "13517   3332_1912      3332_9   3332_1899   1805_1912      1805_9   1805_1899   \n",
      "13518   1393_1912      1393_9   1393_1899   7359_1912      7359_9   7359_1899   \n",
      "\n",
      "      lsg_4_lsg_5 lsg_4_lsg_6 lsg_5_lsg_6  \n",
      "0         1912_10   1912_1899     10_1899  \n",
      "1         1912_10   1912_1488     10_1488  \n",
      "2         1912_10   1912_1913     10_1913  \n",
      "3         1912_10   1912_1734     10_1734  \n",
      "4          1912_9    1912_150       9_150  \n",
      "...           ...         ...         ...  \n",
      "13514      1845_9   1845_1899      9_1899  \n",
      "13515      1786_9   1786_1899      9_1899  \n",
      "13516      1830_9   1830_1899      9_1899  \n",
      "13517      1912_9   1912_1899      9_1899  \n",
      "13518      1912_9   1912_1899      9_1899  \n",
      "\n",
      "[13519 rows x 15 columns]\n",
      "(13519, 105)\n"
     ]
    }
   ],
   "source": [
    "interactiondff3 = createIntercations(interactiondff2,['lsg_1','lsg_2','lsg_3','lsg_4','lsg_5','lsg_6'])\n",
    "\n",
    "interactiontff3 = createIntercations(interactiontff2,['lsg_1','lsg_2','lsg_3','lsg_4','lsg_5','lsg_6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoderExt(object):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n",
    "        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n",
    "        \"\"\"\n",
    "        from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        # self.classes_ = self.label_encoder.classes_\n",
    "\n",
    "    def fit(self, data_list):\n",
    "        \"\"\"\n",
    "        This will fit the encoder for all the unique values and introduce unknown value\n",
    "        :param data_list: A list of string\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
    "        self.classes_ = self.label_encoder.classes_\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_list):\n",
    "        \"\"\"\n",
    "        This will transform the data_list to id list where the new values get assigned to Unknown class\n",
    "        :param data_list:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        new_data_list = list(data_list)\n",
    "        for unique_item in np.unique(data_list):\n",
    "            if unique_item not in self.label_encoder.classes_:\n",
    "                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
    "\n",
    "        return self.label_encoder.transform(new_data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catVar2(data):\n",
    "    categorical_colsT2 = [cname for cname in data.columns if data[cname].dtype == \"object\"]\n",
    "    return categorical_colsT2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robustlabelencoder(train,test):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    label_enc = LabelEncoderExt()\n",
    "    cols = catVar2(train)\n",
    "    print(cols)\n",
    "    for col in cols:\n",
    "        label_enc.fit(train[col])\n",
    "        train[col] = label_enc.transform(train[col])\n",
    "        test[col] = label_enc.transform(test[col])\n",
    "        \n",
    "    print(train.shape,test.shape)\n",
    "    \n",
    "    return train,test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "## delete dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactiondff3['justuk_date1'].dtypes\n",
    "\n",
    "\n",
    "interactiontff3['justuk_date1'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = [cname for cname in interactiondff3.columns if interactiondff3[cname].dtype == \"datetime64[ns]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['instock_date', 'stock_update_date', 'uk_date1', 'uk_date2']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13519, 105)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactiondff3.shape\n",
    "\n",
    "interactiontff3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = interactiondff3.drop(['instock_date', 'stock_update_date', 'uk_date1', 'uk_date2','justinstock_date','juststock_update_date','justuk_date1','justuk_date2','gift_id'],axis =1)*1\n",
    "\n",
    "\n",
    "final_tf = interactiontff3.drop(['instock_date', 'stock_update_date', 'uk_date1', 'uk_date2','justinstock_date','juststock_update_date','justuk_date1','justuk_date2','gift_id'],axis =1)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gift_type', 'gift_category', 'gift_cluster', 'lsg_1', 'lsg_2', 'lsg_3',\n",
       "       'lsg_4', 'lsg_5', 'lsg_6', 'is_discounted', 'volumes',\n",
       "       'DaysStockUpdate', 'buyer12diff', 'buy1buytime', 'buy2buytime',\n",
       "       'stockupdatediff1', 'stockupdatediff2', 'instock_Year', 'instock_Month',\n",
       "       'instock_Week', 'instock_Day', 'instock_Hour', 'instock_Dayofweek',\n",
       "       'instock_Dayofyear', 'instock_Is_month_end', 'instock_Is_month_start',\n",
       "       'instock_Is_quarter_end', 'instock_Is_quarter_start',\n",
       "       'instock_Is_year_end', 'instock_Is_year_start', 'instock_Elapsed',\n",
       "       'stock_update_Year', 'stock_update_Month', 'stock_update_Week',\n",
       "       'stock_update_Day', 'stock_update_Hour', 'stock_update_Dayofweek',\n",
       "       'stock_update_Dayofyear', 'stock_update_Is_month_end',\n",
       "       'stock_update_Is_month_start', 'stock_update_Is_quarter_end',\n",
       "       'stock_update_Is_quarter_start', 'stock_update_Is_year_end',\n",
       "       'stock_update_Is_year_start', 'stock_update_Elapsed', 'uk_date1Year',\n",
       "       'uk_date1Month', 'uk_date1Week', 'uk_date1Day', 'uk_date1Hour',\n",
       "       'uk_date1Dayofweek', 'uk_date1Dayofyear', 'uk_date1Is_month_end',\n",
       "       'uk_date1Is_month_start', 'uk_date1Is_quarter_end',\n",
       "       'uk_date1Is_quarter_start', 'uk_date1Is_year_end',\n",
       "       'uk_date1Is_year_start', 'uk_date1Elapsed', 'uk_date2Year',\n",
       "       'uk_date2Month', 'uk_date2Week', 'uk_date2Day', 'uk_date2Hour',\n",
       "       'uk_date2Dayofweek', 'uk_date2Dayofyear', 'uk_date2Is_month_end',\n",
       "       'uk_date2Is_month_start', 'uk_date2Is_quarter_end',\n",
       "       'uk_date2Is_quarter_start', 'uk_date2Is_year_end',\n",
       "       'uk_date2Is_year_start', 'uk_date2Elapsed',\n",
       "       'Isholidayinstockgrceperiod', 'Isholidaystock_update_dategrceperiod',\n",
       "       'IsholidayUk_date1grceperiod', 'IsholidayUk_date2grceperiod',\n",
       "       'gift_type_gift_category', 'gift_type_gift_cluster',\n",
       "       'gift_category_gift_cluster', 'gift_type_gift_category_gift_cluster',\n",
       "       'lsg_1_lsg_2', 'lsg_1_lsg_3', 'lsg_1_lsg_4', 'lsg_1_lsg_5',\n",
       "       'lsg_1_lsg_6', 'lsg_2_lsg_3', 'lsg_2_lsg_4', 'lsg_2_lsg_5',\n",
       "       'lsg_2_lsg_6', 'lsg_3_lsg_4', 'lsg_3_lsg_5', 'lsg_3_lsg_6',\n",
       "       'lsg_4_lsg_5', 'lsg_4_lsg_6', 'lsg_5_lsg_6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns\n",
    "\n",
    "final_tf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selected finally \n",
    "\n",
    "dtrain = ['uk_date2Elapsed',\n",
    " 'uk_date2Dayofyear',\n",
    " 'uk_date2Day',\n",
    " 'uk_date1Elapsed',\n",
    " 'uk_date1Dayofyear',\n",
    " 'stockupdatediff2',\n",
    " 'stockupdatediff1',\n",
    " 'stock_update_Hour',\n",
    " 'stock_update_Elapsed',\n",
    " 'stock_update_Dayofyear',\n",
    " 'lsg_6',\n",
    " 'lsg_5_lsg_6',\n",
    " 'lsg_3_lsg_6',\n",
    " 'lsg_3_lsg_5',\n",
    " 'lsg_3_lsg_4',\n",
    " 'lsg_3',\n",
    " 'lsg_2_lsg_6',\n",
    " 'lsg_2_lsg_5',\n",
    " 'lsg_2_lsg_4',\n",
    " 'lsg_2_lsg_3',\n",
    " 'lsg_2',\n",
    " 'lsg_1_lsg_3',\n",
    " 'lsg_1_lsg_2',\n",
    " 'lsg_1',\n",
    " 'instock_Elapsed',\n",
    " 'gift_type_gift_cluster',\n",
    " 'gift_type_gift_category_gift_cluster',\n",
    " 'gift_type_gift_category',\n",
    " 'gift_type',\n",
    " 'gift_cluster',\n",
    " 'gift_category_gift_cluster',\n",
    " 'gift_category',\n",
    " 'buyer12diff',\n",
    " 'buy2buytime',\n",
    " 'DaysStockUpdate',\n",
    " 'uk_date2Week',\n",
    " 'uk_date1Week',\n",
    " 'uk_date1Hour',\n",
    " 'stock_update_Week',\n",
    " 'stock_update_Day',\n",
    " 'lsg_4_lsg_6',\n",
    " 'lsg_1_lsg_5',\n",
    " 'lsg_1_lsg_4',\n",
    " 'is_discounted',\n",
    " 'instock_Week',\n",
    " 'instock_Hour',\n",
    " 'instock_Dayofyear',\n",
    " 'instock_Day',\n",
    " 'buy1buytime',\n",
    " 'volumes',\n",
    " 'uk_date2Month',\n",
    " 'uk_date2Hour',\n",
    " 'uk_date2Dayofweek',\n",
    " 'uk_date1Month',\n",
    " 'uk_date1Is_quarter_end',\n",
    " 'uk_date1Is_month_end',\n",
    " 'uk_date1Dayofweek',\n",
    " 'uk_date1Day',\n",
    " 'stock_update_Dayofweek',\n",
    " 'lsg_5',\n",
    " 'lsg_4_lsg_5',\n",
    " 'lsg_4',\n",
    " 'lsg_1_lsg_6',\n",
    " 'instock_Year',\n",
    " 'instock_Month',\n",
    " 'instock_Is_quarter_start',\n",
    " 'instock_Is_quarter_end',\n",
    " 'instock_Dayofweek',\n",
    " 'Isholidayinstockgrceperiod',\n",
    " 'IsholidayUk_date2grceperiod','price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selected finally \n",
    "\n",
    "dtest = ['uk_date2Elapsed',\n",
    " 'uk_date2Dayofyear',\n",
    " 'uk_date2Day',\n",
    " 'uk_date1Elapsed',\n",
    " 'uk_date1Dayofyear',\n",
    " 'stockupdatediff2',\n",
    " 'stockupdatediff1',\n",
    " 'stock_update_Hour',\n",
    " 'stock_update_Elapsed',\n",
    " 'stock_update_Dayofyear',\n",
    " 'lsg_6',\n",
    " 'lsg_5_lsg_6',\n",
    " 'lsg_3_lsg_6',\n",
    " 'lsg_3_lsg_5',\n",
    " 'lsg_3_lsg_4',\n",
    " 'lsg_3',\n",
    " 'lsg_2_lsg_6',\n",
    " 'lsg_2_lsg_5',\n",
    " 'lsg_2_lsg_4',\n",
    " 'lsg_2_lsg_3',\n",
    " 'lsg_2',\n",
    " 'lsg_1_lsg_3',\n",
    " 'lsg_1_lsg_2',\n",
    " 'lsg_1',\n",
    " 'instock_Elapsed',\n",
    " 'gift_type_gift_cluster',\n",
    " 'gift_type_gift_category_gift_cluster',\n",
    " 'gift_type_gift_category',\n",
    " 'gift_type',\n",
    " 'gift_cluster',\n",
    " 'gift_category_gift_cluster',\n",
    " 'gift_category',\n",
    " 'buyer12diff',\n",
    " 'buy2buytime',\n",
    " 'DaysStockUpdate',\n",
    " 'uk_date2Week',\n",
    " 'uk_date1Week',\n",
    " 'uk_date1Hour',\n",
    " 'stock_update_Week',\n",
    " 'stock_update_Day',\n",
    " 'lsg_4_lsg_6',\n",
    " 'lsg_1_lsg_5',\n",
    " 'lsg_1_lsg_4',\n",
    " 'is_discounted',\n",
    " 'instock_Week',\n",
    " 'instock_Hour',\n",
    " 'instock_Dayofyear',\n",
    " 'instock_Day',\n",
    " 'buy1buytime',\n",
    " 'volumes',\n",
    " 'uk_date2Month',\n",
    " 'uk_date2Hour',\n",
    " 'uk_date2Dayofweek',\n",
    " 'uk_date1Month',\n",
    " 'uk_date1Is_quarter_end',\n",
    " 'uk_date1Is_month_end',\n",
    " 'uk_date1Dayofweek',\n",
    " 'uk_date1Day',\n",
    " 'stock_update_Dayofweek',\n",
    " 'lsg_5',\n",
    " 'lsg_4_lsg_5',\n",
    " 'lsg_4',\n",
    " 'lsg_1_lsg_6',\n",
    " 'instock_Year',\n",
    " 'instock_Month',\n",
    " 'instock_Is_quarter_start',\n",
    " 'instock_Is_quarter_end',\n",
    " 'instock_Dayofweek',\n",
    " 'Isholidayinstockgrceperiod',\n",
    " 'IsholidayUk_date2grceperiod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.isna().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gift_type_gift_category', 'gift_type_gift_cluster', 'gift_category_gift_cluster', 'gift_type_gift_category_gift_cluster', 'lsg_1_lsg_2', 'lsg_1_lsg_3', 'lsg_1_lsg_4', 'lsg_1_lsg_5', 'lsg_1_lsg_6', 'lsg_2_lsg_3', 'lsg_2_lsg_4', 'lsg_2_lsg_5', 'lsg_2_lsg_6', 'lsg_3_lsg_4', 'lsg_3_lsg_5', 'lsg_3_lsg_6', 'lsg_4_lsg_5', 'lsg_4_lsg_6', 'lsg_5_lsg_6']\n",
      "(20279, 97) (13519, 96)\n"
     ]
    }
   ],
   "source": [
    "final_dfenc,final_tfenc = robustlabelencoder(final_df,final_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_tfenc.isna().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buy2buytime\t7389\t36.4\n",
    "# stockupdatediff1\t3885\t19.2\n",
    "# stockupdatediff2\t3881\t19.1\n",
    "# buy1buytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_dfenc['buy2buytime'] = np.absolute(final_dfenc['buy2buytime'])\n",
    "\n",
    "# final_dfenc['stockupdatediff1'] = np.absolute(final_dfenc['stockupdatediff1'])\n",
    "\n",
    "# final_dfenc['stockupdatediff2'] = np.absolute(final_dfenc['stockupdatediff2'])\n",
    "\n",
    "# final_dfenc['buy1buytime'] = np.absolute(final_dfenc['buy1buytime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_tfenc['buy2buytime'] = np.absolute(final_tfenc['buy2buytime'])\n",
    "\n",
    "# final_tfenc['stockupdatediff1'] = np.absolute(final_tfenc['stockupdatediff1'])\n",
    "\n",
    "# final_tfenc['stockupdatediff2'] = np.absolute(final_tfenc['stockupdatediff2'])\n",
    "\n",
    "# final_tfenc['buy1buytime'] = np.absolute(final_tfenc['buy1buytime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numeric_feats = (final_dfenc.drop(['price'],axis=1)).dtypes[final_dfenc.dtypes != \"object\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numeric_feats = numeric_feats.drop(['buy2buytime','stockupdatediff1','stockupdatediff2','buy1buytime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numeric_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############# skewnesss removal\n",
    "# from scipy.stats import norm, skew #for some statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #numeric_feats = (final_dfenc.drop(['price'],axis=1)).dtypes[final_dfenc.dtypes != \"object\"].index\n",
    "\n",
    "# # Check the skew of all numerical features\n",
    "# skewed_feats = final_dfenc[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "# print(\"\\nSkew in numerical features: \\n\")\n",
    "# skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "# skewness.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skewness = skewness[abs(skewness) > 0.75]\n",
    "# print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "# from scipy.special import boxcox1p\n",
    "# skewed_features = skewness.index\n",
    "# lam = 0.15\n",
    "# for feat in skewed_features:\n",
    "#     #all_data[feat] += 1\n",
    "#     final_dfenc[feat] = boxcox1p(final_dfenc[feat], lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skewness = skewness[abs(skewness) > 0.75]\n",
    "# print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "# from scipy.special import boxcox1p\n",
    "# skewed_features = skewness.index\n",
    "# lam = 0.15\n",
    "# for feat in skewed_features:\n",
    "#     #all_data[feat] += 1\n",
    "#     final_tf[feat] = boxcox1p(final_tf[feat], lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data,fitted_lambda = stats.boxcox(train)\n",
    "\n",
    "# # use lambda value to transform test data\n",
    "# test_data = stats.boxcox(test, fitted_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_dfenc,final_tfenc = robustlabelencoder(final_df,final_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dfencRed = final_dfenc[dtrain]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tfencRed = final_tfenc[dtest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dfencRed.to_csv('finaltrainBOCO.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tfencRed.to_csv('finaltestBOCO.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
